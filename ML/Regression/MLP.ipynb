{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '../preped.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Select features and target\n",
    "features = ['Hidden Gem Score', 'Runtime', 'Awards Received', 'Awards Nominated For',\n",
    "           'Boxoffice', 'IMDb Votes', 'Minimum Age'] + \\\n",
    "           [col for col in df.columns if col in ['Action', 'Adventure', 'Animation', \n",
    "           'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', \n",
    "           'Fantasy', 'History', 'Horror', 'Music', 'Musical', 'Mystery', \n",
    "           'News', 'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western']]\n",
    "\n",
    "target = 'IMDb Score'\n",
    "\n",
    "# Preprocessing\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_imdb = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred_imdb))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred_imdb))\n",
    "print(f'R2 Score: {r2_score(y_test, y_pred_imdb):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rt = df['Rotten Tomatoes Score']\n",
    "\n",
    "# Split data (using same X from before)\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = train_test_split(X, y_rt, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train MLP model\n",
    "mlp_rt = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "mlp_rt.fit(X_train, y_train_rt)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rt = mlp_rt.predict(X_test)\n",
    "\n",
    "# Print metrics for Rotten Tomatoes\n",
    "print('\\nMetrics for Rotten Tomatoes Score:')\n",
    "print('Mean Absolute Error:', f'{mean_absolute_error(y_test_rt, y_pred_rt):.3f}')\n",
    "print('Mean Squared Error:', f'{mean_squared_error(y_test_rt, y_pred_rt):.3f}')\n",
    "print('R2 Score:', f'{r2_score(y_test_rt, y_pred_rt):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mc = df['Metacritic Score']\n",
    "\n",
    "# Split data (using same X from before)\n",
    "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(X, y_mc, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train MLP model\n",
    "mlp_mc = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "mlp_mc.fit(X_train, y_train_mc)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_mc = mlp_mc.predict(X_test)\n",
    "\n",
    "# Print metrics for Metacritic\n",
    "print('\\nMetrics for Metacritic Score:')\n",
    "print('Mean Absolute Error:', f'{mean_absolute_error(y_test_mc, y_pred_mc):.3f}')\n",
    "print('Mean Squared Error:', f'{mean_squared_error(y_test_mc, y_pred_mc):.3f}')\n",
    "print('R2 Score:', f'{r2_score(y_test_mc, y_pred_mc):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with subplots\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot IMDb scores\n",
    "plt.subplot(131)\n",
    "plt.scatter(y_test, y_pred_imdb, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual IMDb Score')\n",
    "plt.ylabel('Predicted IMDb Score')\n",
    "plt.title('IMDb Scores')\n",
    "\n",
    "# Plot Metacritic scores \n",
    "plt.subplot(132)\n",
    "plt.scatter(y_test_mc, y_pred_mc, alpha=0.6)\n",
    "plt.plot([y_test_mc.min(), y_test_mc.max()], [y_test_mc.min(), y_test_mc.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Metacritic Score')\n",
    "plt.ylabel('Predicted Metacritic Score')\n",
    "plt.title('Metacritic Scores')\n",
    "\n",
    "# Plot Rotten Tomatoes scores\n",
    "plt.subplot(133)\n",
    "plt.scatter(y_test_rt, y_pred_rt, alpha=0.6)\n",
    "plt.plot([y_test_rt.min(), y_test_rt.max()], [y_test_rt.min(), y_test_rt.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Rotten Tomatoes Score') \n",
    "plt.ylabel('Predicted Rotten Tomatoes Score')\n",
    "plt.title('Rotten Tomatoes Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize using HalvingGridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# Define the parameter grid for HalvingGridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100, 50), (200, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "# Define the target columns\n",
    "target_im = 'IMDb Score'\n",
    "target_rt = 'Rotten Tomatoes Score'\n",
    "target_mc = 'Metacritic Score'\n",
    "\n",
    "targets = {\n",
    "    target_im: {},\n",
    "    target_rt: {},\n",
    "    target_mc: {}\n",
    "}\n",
    "\n",
    "for target_name, target_data in targets.items():\n",
    "    y = df[target_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    targets[target_name]['X_train_scaled'] = X_train_scaled\n",
    "    targets[target_name]['X_test_scaled'] = X_test_scaled\n",
    "    targets[target_name]['y_train'] = y_train\n",
    "    targets[target_name]['y_test'] = y_test\n",
    "    targets[target_name]['scaler'] = scaler\n",
    "\n",
    "    # Perform HalvingGridSearchCV\n",
    "    model = MLPRegressor(max_iter=1000, random_state=42)\n",
    "    halving_search = HalvingGridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1, factor=2, min_resources=50)\n",
    "    halving_search.fit(X_train_scaled, y_train)\n",
    "    best_model = halving_search.best_estimator_\n",
    "\n",
    "    # Make predictions using the best model\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f'Best Parameters for {target_name}: {halving_search.best_params_}')\n",
    "    print(f'R^2 Score for {target_name}: {r2:.3f}')\n",
    "    \n",
    "    targets[target_name]['best_model'] = best_model\n",
    "    targets[target_name]['halving_search'] = halving_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters for IMDb Score: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (200, 100), 'learning_rate': 'constant', 'solver': 'sgd'}\\\n",
    "R^2 Score for IMDb Score: 0.722\\\n",
    "Best Parameters for Rotten Tomatoes Score: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'learning_rate': 'constant', 'solver': 'sgd'}\\\n",
    "R^2 Score for Rotten Tomatoes Score: 0.876\\\n",
    "Best Parameters for Metacritic Score: {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'sgd'}\\\n",
    "R^2 Score for Metacritic Score: 0.815"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imdb_best = targets[target_im]['best_model']\n",
    "rt_best = targets[target_rt]['best_model']\n",
    "mc_best = targets[target_mc]['best_model']\n",
    "\n",
    "# Create a figure with subplots\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot IMDb scores using the best model\n",
    "plt.subplot(131)\n",
    "y_pred_imdb_best = imdb_best.predict(targets[target_im]['X_test_scaled'])\n",
    "plt.scatter(targets[target_im]['y_test'], y_pred_imdb_best, alpha=0.6)\n",
    "plt.plot([targets[target_im]['y_test'].min(), targets[target_im]['y_test'].max()], \n",
    "         [targets[target_im]['y_test'].min(), targets[target_im]['y_test'].max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual IMDb Score')\n",
    "plt.ylabel('Predicted IMDb Score')\n",
    "plt.title('Best IMDb Scores')\n",
    "\n",
    "# Plot Metacritic scores using the best model\n",
    "plt.subplot(132)\n",
    "y_pred_mc_best = mc_best.predict(targets[target_mc]['X_test_scaled'])\n",
    "plt.scatter(targets[target_mc]['y_test'], y_pred_mc_best, alpha=0.6)\n",
    "plt.plot([targets[target_mc]['y_test'].min(), targets[target_mc]['y_test'].max()], \n",
    "         [targets[target_mc]['y_test'].min(), targets[target_mc]['y_test'].max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Metacritic Score')\n",
    "plt.ylabel('Predicted Metacritic Score')\n",
    "plt.title('Best Metacritic Scores')\n",
    "\n",
    "# Plot Rotten Tomatoes scores using the best model\n",
    "plt.subplot(133)\n",
    "y_pred_rt_best = rt_best.predict(targets[target_rt]['X_test_scaled'])\n",
    "plt.scatter(targets[target_rt]['y_test'], y_pred_rt_best, alpha=0.6)\n",
    "plt.plot([targets[target_rt]['y_test'].min(), targets[target_rt]['y_test'].max()], \n",
    "         [targets[target_rt]['y_test'].min(), targets[target_rt]['y_test'].max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Rotten Tomatoes Score')\n",
    "plt.ylabel('Predicted Rotten Tomatoes Score')\n",
    "plt.title('Best Rotten Tomatoes Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
