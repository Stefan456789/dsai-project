{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = '../preped.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Is Series', 'Hidden Gem Score', 'Runtime', 'IMDb Score',\n",
      "       'Rotten Tomatoes Score', 'Metacritic Score', 'Awards Received',\n",
      "       'Awards Nominated For', 'Boxoffice', 'Release Date', 'IMDb Votes',\n",
      "       'Minimum Age', 'Action', 'Adventure', 'Animation', 'Biography',\n",
      "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
      "       'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Romance',\n",
      "       'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Adult\n",
       "1       Adult\n",
       "2       Adult\n",
       "3        Teen\n",
       "4        Teen\n",
       "        ...  \n",
       "2504     Teen\n",
       "2505     Teen\n",
       "2506     Teen\n",
       "2507     Teen\n",
       "2508     Teen\n",
       "Name: Age Group, Length: 2509, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define age groups\n",
    "def age_group(age):\n",
    "    if age == 0:\n",
    "        return 'All'\n",
    "    elif 1 <= age <= 16:\n",
    "        return 'Teen'\n",
    "    else:\n",
    "        return 'Adult'\n",
    "df['Age Group'] = df['Minimum Age'].apply(age_group)\n",
    "\n",
    "df['Age Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Adult       0.61      0.74      0.67       216\n",
      "         All       0.61      0.33      0.43        58\n",
      "        Teen       0.70      0.64      0.67       228\n",
      "\n",
      "    accuracy                           0.65       502\n",
      "   macro avg       0.64      0.57      0.59       502\n",
      "weighted avg       0.65      0.65      0.64       502\n",
      "\n",
      "Accuracy: 0.6454183266932271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "features = df.drop(columns=['Minimum Age', 'Age Group']).select_dtypes(include=[int, float])\n",
    "\n",
    "X = features\n",
    "y = df['Age Group']\n",
    "\n",
    "# 3. Feature Scaling (Essential for KNN):\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Split data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42) # Adjust test size as needed\n",
    "\n",
    "# Train the KNN model:\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # Choose an appropriate value for k (n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set:\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model:\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 8\n",
      "n_required_iterations: 8\n",
      "n_possible_iterations: 8\n",
      "min_resources_: 10\n",
      "max_resources_: 2007\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 174\n",
      "n_resources: 10\n",
      "Fitting 5 folds for each of 174 candidates, totalling 870 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3 0.3 0.4 0.3 0.3 0.1 0.1 0.1 0.3 0.1 0.3 0.3 0.5 0.3 nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan 0.3 nan 0.3 nan 0.1 nan 0.1 nan 0.1 nan 0.1 nan 0.3\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan 0.3 0.3 0.4 0.3 0.3 0.1 0.1 0.1 0.3 0.1\n",
      " 0.3 0.3 0.5 0.3 nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 87\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 87 candidates, totalling 435 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65      ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64      ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 2\n",
      "n_candidates: 44\n",
      "n_resources: 40\n",
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65       0.53571429 0.45714286 0.45714286\n",
      " 0.51428571 0.48928571 0.48928571 0.46071429 0.46071429 0.46428571\n",
      " 0.46428571 0.57142857 0.57142857 0.57142857 0.57142857 0.57142857\n",
      " 0.57142857 0.42857143 0.48214286 0.48214286 0.42857143 0.46071429\n",
      " 0.45714286 0.48214286 0.40357143 0.45714286 0.46071429 0.45714286\n",
      " 0.48214286 0.45714286 0.48571429 0.45714286 0.48571429 0.48928571\n",
      " 0.48928571 0.51785714 0.51785714 0.43571429 0.43571429 0.46071429\n",
      " 0.43928571 0.51428571 0.46071429 0.46071429 0.37857143]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64       0.72802419 0.64596774 0.64596774\n",
      " 1.         1.         1.         0.76552419 0.76552419 0.63951613\n",
      " 0.63951613 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.62016129 1.         1.         1.         1.         0.62016129\n",
      " 1.         1.         1.         1.         1.         0.65826613\n",
      " 0.65826613 0.68346774 0.68346774 0.70887097 0.70887097 0.66451613\n",
      " 0.66451613 0.6266129  0.66451613 1.         0.67701613]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65       0.53571429 0.45714286 0.45714286\n",
      " 0.51428571 0.48928571 0.48928571 0.46071429 0.46071429 0.46428571\n",
      " 0.46428571 0.57142857 0.57142857 0.57142857 0.57142857 0.57142857\n",
      " 0.57142857 0.42857143 0.48214286 0.48214286 0.42857143 0.46071429\n",
      " 0.45714286 0.48214286 0.40357143 0.45714286 0.46071429 0.45714286\n",
      " 0.48214286 0.45714286 0.48571429 0.45714286 0.48571429 0.48928571\n",
      " 0.48928571 0.51785714 0.51785714 0.43571429 0.43571429 0.46071429\n",
      " 0.43928571 0.51428571 0.46071429 0.46071429 0.37857143 0.60916667\n",
      " 0.58333333 0.62333333 0.58333333 0.62333333 0.60833333 0.60833333\n",
      " 0.59666667 0.57       0.57       0.59666667 0.5975     0.5425\n",
      " 0.60916667 0.60916667 0.60583333 0.47666667 0.47666667 0.47666667\n",
      " 0.47666667 0.47666667 0.47666667]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64       0.72802419 0.64596774 0.64596774\n",
      " 1.         1.         1.         0.76552419 0.76552419 0.63951613\n",
      " 0.63951613 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.62016129 1.         1.         1.         1.         0.62016129\n",
      " 1.         1.         1.         1.         1.         0.65826613\n",
      " 0.65826613 0.68346774 0.68346774 0.70887097 0.70887097 0.66451613\n",
      " 0.66451613 0.6266129  0.66451613 1.         0.67701613 0.64747024\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.67886905 1.         1.         0.67886905 0.65689484 1.\n",
      " 0.70744048 0.70744048 0.73878968 1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 3\n",
      "n_candidates: 22\n",
      "n_resources: 80\n",
      "Fitting 5 folds for each of 22 candidates, totalling 110 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 11\n",
      "n_resources: 160\n",
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65       0.53571429 0.45714286 0.45714286\n",
      " 0.51428571 0.48928571 0.48928571 0.46071429 0.46071429 0.46428571\n",
      " 0.46428571 0.57142857 0.57142857 0.57142857 0.57142857 0.57142857\n",
      " 0.57142857 0.42857143 0.48214286 0.48214286 0.42857143 0.46071429\n",
      " 0.45714286 0.48214286 0.40357143 0.45714286 0.46071429 0.45714286\n",
      " 0.48214286 0.45714286 0.48571429 0.45714286 0.48571429 0.48928571\n",
      " 0.48928571 0.51785714 0.51785714 0.43571429 0.43571429 0.46071429\n",
      " 0.43928571 0.51428571 0.46071429 0.46071429 0.37857143 0.60916667\n",
      " 0.58333333 0.62333333 0.58333333 0.62333333 0.60833333 0.60833333\n",
      " 0.59666667 0.57       0.57       0.59666667 0.5975     0.5425\n",
      " 0.60916667 0.60916667 0.60583333 0.47666667 0.47666667 0.47666667\n",
      " 0.47666667 0.47666667 0.47666667 0.61149194 0.61149194 0.60504032\n",
      " 0.55362903 0.58568548 0.58568548 0.60504032 0.57298387 0.57298387\n",
      " 0.54778226 0.54778226]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64       0.72802419 0.64596774 0.64596774\n",
      " 1.         1.         1.         0.76552419 0.76552419 0.63951613\n",
      " 0.63951613 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.62016129 1.         1.         1.         1.         0.62016129\n",
      " 1.         1.         1.         1.         1.         0.65826613\n",
      " 0.65826613 0.68346774 0.68346774 0.70887097 0.70887097 0.66451613\n",
      " 0.66451613 0.6266129  0.66451613 1.         0.67701613 0.64747024\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.67886905 1.         1.         0.67886905 0.65689484 1.\n",
      " 0.70744048 0.70744048 0.73878968 1.         1.         1.\n",
      " 1.         1.         1.         0.70853839 0.70853839 0.69127707\n",
      " 0.76003937 1.         1.         0.68806594 0.75082431 0.75082431\n",
      " 1.         1.        ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65       0.53571429 0.45714286 0.45714286\n",
      " 0.51428571 0.48928571 0.48928571 0.46071429 0.46071429 0.46428571\n",
      " 0.46428571 0.57142857 0.57142857 0.57142857 0.57142857 0.57142857\n",
      " 0.57142857 0.42857143 0.48214286 0.48214286 0.42857143 0.46071429\n",
      " 0.45714286 0.48214286 0.40357143 0.45714286 0.46071429 0.45714286\n",
      " 0.48214286 0.45714286 0.48571429 0.45714286 0.48571429 0.48928571\n",
      " 0.48928571 0.51785714 0.51785714 0.43571429 0.43571429 0.46071429\n",
      " 0.43928571 0.51428571 0.46071429 0.46071429 0.37857143 0.60916667\n",
      " 0.58333333 0.62333333 0.58333333 0.62333333 0.60833333 0.60833333\n",
      " 0.59666667 0.57       0.57       0.59666667 0.5975     0.5425\n",
      " 0.60916667 0.60916667 0.60583333 0.47666667 0.47666667 0.47666667\n",
      " 0.47666667 0.47666667 0.47666667 0.61149194 0.61149194 0.60504032\n",
      " 0.55362903 0.58568548 0.58568548 0.60504032 0.57298387 0.57298387\n",
      " 0.54778226 0.54778226 0.61478175 0.61478175 0.59915675 0.63080357\n",
      " 0.61790675 0.61790675]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64       0.72802419 0.64596774 0.64596774\n",
      " 1.         1.         1.         0.76552419 0.76552419 0.63951613\n",
      " 0.63951613 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.62016129 1.         1.         1.         1.         0.62016129\n",
      " 1.         1.         1.         1.         1.         0.65826613\n",
      " 0.65826613 0.68346774 0.68346774 0.70887097 0.70887097 0.66451613\n",
      " 0.66451613 0.6266129  0.66451613 1.         0.67701613 0.64747024\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.67886905 1.         1.         0.67886905 0.65689484 1.\n",
      " 0.70744048 0.70744048 0.73878968 1.         1.         1.\n",
      " 1.         1.         1.         0.70853839 0.70853839 0.69127707\n",
      " 0.76003937 1.         1.         0.68806594 0.75082431 0.75082431\n",
      " 1.         1.         1.         1.         0.71749694 0.70811275\n",
      " 0.72690564 0.72690564]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65       0.53571429 0.45714286 0.45714286\n",
      " 0.51428571 0.48928571 0.48928571 0.46071429 0.46071429 0.46428571\n",
      " 0.46428571 0.57142857 0.57142857 0.57142857 0.57142857 0.57142857\n",
      " 0.57142857 0.42857143 0.48214286 0.48214286 0.42857143 0.46071429\n",
      " 0.45714286 0.48214286 0.40357143 0.45714286 0.46071429 0.45714286\n",
      " 0.48214286 0.45714286 0.48571429 0.45714286 0.48571429 0.48928571\n",
      " 0.48928571 0.51785714 0.51785714 0.43571429 0.43571429 0.46071429\n",
      " 0.43928571 0.51428571 0.46071429 0.46071429 0.37857143 0.60916667\n",
      " 0.58333333 0.62333333 0.58333333 0.62333333 0.60833333 0.60833333\n",
      " 0.59666667 0.57       0.57       0.59666667 0.5975     0.5425\n",
      " 0.60916667 0.60916667 0.60583333 0.47666667 0.47666667 0.47666667\n",
      " 0.47666667 0.47666667 0.47666667 0.61149194 0.61149194 0.60504032\n",
      " 0.55362903 0.58568548 0.58568548 0.60504032 0.57298387 0.57298387\n",
      " 0.54778226 0.54778226 0.61478175 0.61478175 0.59915675 0.63080357\n",
      " 0.61790675 0.61790675 0.61390256 0.61390256 0.61865157]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64       0.72802419 0.64596774 0.64596774\n",
      " 1.         1.         1.         0.76552419 0.76552419 0.63951613\n",
      " 0.63951613 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.62016129 1.         1.         1.         1.         0.62016129\n",
      " 1.         1.         1.         1.         1.         0.65826613\n",
      " 0.65826613 0.68346774 0.68346774 0.70887097 0.70887097 0.66451613\n",
      " 0.66451613 0.6266129  0.66451613 1.         0.67701613 0.64747024\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.67886905 1.         1.         0.67886905 0.65689484 1.\n",
      " 0.70744048 0.70744048 0.73878968 1.         1.         1.\n",
      " 1.         1.         1.         0.70853839 0.70853839 0.69127707\n",
      " 0.76003937 1.         1.         0.68806594 0.75082431 0.75082431\n",
      " 1.         1.         1.         1.         0.71749694 0.70811275\n",
      " 0.72690564 0.72690564 0.71736103 0.71736103 0.69780914]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 5\n",
      "n_candidates: 6\n",
      "n_resources: 320\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 3\n",
      "n_resources: 640\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 2\n",
      "n_resources: 1280\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.3        0.3        0.4        0.3        0.3        0.1\n",
      " 0.1        0.1        0.3        0.1        0.3        0.3\n",
      " 0.5        0.3               nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.3\n",
      "        nan 0.3               nan 0.1               nan 0.1\n",
      "        nan 0.1               nan 0.1               nan 0.3\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.3        0.3        0.4        0.3\n",
      " 0.3        0.1        0.1        0.1        0.3        0.1\n",
      " 0.3        0.3        0.5        0.3               nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58333333 0.65       0.65       0.65       0.55       0.6\n",
      " 0.45       0.6        0.71666667 0.65       0.71666667 0.71666667\n",
      " 0.71666667 0.65       0.58333333 0.65       0.65       0.65\n",
      " 0.55       0.6        0.45       0.6        0.45       0.45\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.53333333 0.55\n",
      " 0.55       0.48333333 0.53333333 0.48333333 0.66666667 0.53333333\n",
      " 0.48333333 0.66666667 0.53333333 0.55       0.65       0.71666667\n",
      " 0.65       0.65       0.48333333 0.53333333 0.53333333 0.58333333\n",
      " 0.58333333 0.58333333 0.53333333 0.58333333 0.58333333 0.58333333\n",
      " 0.65       0.53333333 0.71666667 0.65       0.65       0.56666667\n",
      " 0.56666667 0.65       0.65       0.53571429 0.45714286 0.45714286\n",
      " 0.51428571 0.48928571 0.48928571 0.46071429 0.46071429 0.46428571\n",
      " 0.46428571 0.57142857 0.57142857 0.57142857 0.57142857 0.57142857\n",
      " 0.57142857 0.42857143 0.48214286 0.48214286 0.42857143 0.46071429\n",
      " 0.45714286 0.48214286 0.40357143 0.45714286 0.46071429 0.45714286\n",
      " 0.48214286 0.45714286 0.48571429 0.45714286 0.48571429 0.48928571\n",
      " 0.48928571 0.51785714 0.51785714 0.43571429 0.43571429 0.46071429\n",
      " 0.43928571 0.51428571 0.46071429 0.46071429 0.37857143 0.60916667\n",
      " 0.58333333 0.62333333 0.58333333 0.62333333 0.60833333 0.60833333\n",
      " 0.59666667 0.57       0.57       0.59666667 0.5975     0.5425\n",
      " 0.60916667 0.60916667 0.60583333 0.47666667 0.47666667 0.47666667\n",
      " 0.47666667 0.47666667 0.47666667 0.61149194 0.61149194 0.60504032\n",
      " 0.55362903 0.58568548 0.58568548 0.60504032 0.57298387 0.57298387\n",
      " 0.54778226 0.54778226 0.61478175 0.61478175 0.59915675 0.63080357\n",
      " 0.61790675 0.61790675 0.61390256 0.61390256 0.61865157 0.63822304\n",
      " 0.64762561]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stefa\\miniconda3\\envs\\sklearn-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.76428571 1.         0.76428571 1.\n",
      " 0.73928571 1.         0.78928571 1.         0.73928571 1.\n",
      " 0.66428571 1.                nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan 1.                nan 1.                nan 1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 1.         1.         0.76428571 1.\n",
      " 0.76428571 1.         0.73928571 1.         0.78928571 1.\n",
      " 0.73928571 1.         0.66428571 1.                nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62666667 1.         0.58833333 1.         0.64166667 1.\n",
      " 0.615      1.         0.66416667 1.         0.62583333 1.\n",
      " 0.63916667 1.         0.62666667 1.         0.58833333 1.\n",
      " 0.64166667 1.         0.615      1.         0.615      1.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         0.74333333 1.\n",
      " 1.         0.74333333 1.         1.         0.665      0.70333333\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.74166667 1.         1.         1.\n",
      " 0.665      0.74166667 0.70333333 1.         1.         0.74333333\n",
      " 0.74333333 0.64       0.64       0.72802419 0.64596774 0.64596774\n",
      " 1.         1.         1.         0.76552419 0.76552419 0.63951613\n",
      " 0.63951613 1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.62016129 1.         1.         1.         1.         0.62016129\n",
      " 1.         1.         1.         1.         1.         0.65826613\n",
      " 0.65826613 0.68346774 0.68346774 0.70887097 0.70887097 0.66451613\n",
      " 0.66451613 0.6266129  0.66451613 1.         0.67701613 0.64747024\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.67886905 1.         1.         0.67886905 0.65689484 1.\n",
      " 0.70744048 0.70744048 0.73878968 1.         1.         1.\n",
      " 1.         1.         1.         0.70853839 0.70853839 0.69127707\n",
      " 0.76003937 1.         1.         0.68806594 0.75082431 0.75082431\n",
      " 1.         1.         1.         1.         0.71749694 0.70811275\n",
      " 0.72690564 0.72690564 0.71736103 0.71736103 0.69780914 0.73192357\n",
      " 0.71004227]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "features = df.drop(columns=['Minimum Age', 'Age Group']).select_dtypes(include=[int, float])\n",
    "\n",
    "X = features\n",
    "y = df['Age Group']\n",
    "\n",
    "# 3. Feature Scaling (Essential for KNN):\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42) # Adjust test size as needed\n",
    "\n",
    "# Define the parameter grid for HalvingGridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1, 30),  # Explore a range of n_neighbors values\n",
    "    'weights': ['uniform', 'distance'], # Explore different weighting strategies\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'] # Explore different distance metrics\n",
    "}\n",
    "\n",
    "# Initialize HalvingGridSearchCV\n",
    "halving_cv = HalvingGridSearchCV(\n",
    "    KNeighborsClassifier(), \n",
    "    param_grid, \n",
    "    cv=5,  # Number of cross-validation folds\n",
    "    scoring='accuracy',  # Scoring metric\n",
    "    n_jobs=-1, # Use all available cores for parallel processing\n",
    "    verbose=1, #  Increase verbosity for more detailed output\n",
    "    factor=2, # Reduction factor for resources (e.g., half the candidates in each iteration)\n",
    "    min_resources=10 # Minimum resources to start with\n",
    ")\n",
    "\n",
    "# Train the model using HalvingGridSearchCV\n",
    "halving_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator from HalvingGridSearchCV\n",
    "best_knn = halving_cv.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred = best_knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Adult       0.60      0.76      0.67       216\n",
      "         All       0.54      0.24      0.33        58\n",
      "        Teen       0.73      0.65      0.69       228\n",
      "\n",
      "    accuracy                           0.65       502\n",
      "   macro avg       0.62      0.55      0.56       502\n",
      "weighted avg       0.65      0.65      0.64       502\n",
      "\n",
      "Accuracy: 0.649402390438247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model:\n",
    "print(\"Best Hyperparameters:\", halving_cv.best_params_)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
