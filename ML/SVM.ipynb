{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "file_path = '../preped.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Select features and target\n",
    "features = ['Hidden Gem Score', 'Runtime', 'Awards Received', 'Awards Nominated For',\n",
    "           'Boxoffice', 'IMDb Votes', 'Minimum Age'] + \\\n",
    "           [col for col in df.columns if col in ['Action', 'Adventure', 'Animation', \n",
    "           'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', \n",
    "           'Fantasy', 'History', 'Horror', 'Music', 'Musical', 'Mystery', \n",
    "           'News', 'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western']]\n",
    "\n",
    "target = 'IMDb Score'\n",
    "\n",
    "X = df[features]\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target columns\n",
    "target_im = 'IMDb Score'\n",
    "target_rt = 'Rotten Tomatoes Score'\n",
    "target_mc = 'Metacritic Score'\n",
    "\n",
    "# Prepare data for IMDb Score\n",
    "y_im = df[target_im]\n",
    "X_train_im, X_test_im, y_train_im, y_test_im = train_test_split(X, y_im, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare data for Rotten Tomatoes Score\n",
    "y_rt = df[target_rt]\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = train_test_split(X, y_rt, test_size=0.2, random_state=42)\n",
    "\n",
    "# Prepare data for Metacritic Score\n",
    "y_mc = df[target_mc]\n",
    "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(X, y_mc, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features (reusing existing scaler)\n",
    "X_train_im_scaled = scaler.fit_transform(X_train_im)\n",
    "X_test_im_scaled = scaler.transform(X_test_im)\n",
    "X_train_rt_scaled = scaler.fit_transform(X_train_rt)\n",
    "X_test_rt_scaled = scaler.transform(X_test_rt)\n",
    "X_train_mc_scaled = scaler.fit_transform(X_train_mc)\n",
    "X_test_mc_scaled = scaler.transform(X_test_mc)\n",
    "\n",
    "# Train models\n",
    "model_im = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "model_rt = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "model_mc = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "model_im.fit(X_train_im_scaled, y_train_im)\n",
    "model_rt.fit(X_train_rt_scaled, y_train_rt)\n",
    "model_mc.fit(X_train_mc_scaled, y_train_mc)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_im = model_im.predict(X_test_im_scaled)\n",
    "y_pred_rt = model_rt.predict(X_test_rt_scaled)\n",
    "y_pred_mc = model_mc.predict(X_test_mc_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "mae_im = mean_absolute_error(y_test_im, y_pred_im)\n",
    "mse_im = mean_squared_error(y_test_im, y_pred_im)\n",
    "r2_im = r2_score(y_test_im, y_pred_im)\n",
    "\n",
    "mae_rt = mean_absolute_error(y_test_rt, y_pred_rt)\n",
    "mse_rt = mean_squared_error(y_test_rt, y_pred_rt)\n",
    "r2_rt = r2_score(y_test_rt, y_pred_rt)\n",
    "\n",
    "mae_mc = mean_absolute_error(y_test_mc, y_pred_mc)\n",
    "mse_mc = mean_squared_error(y_test_mc, y_pred_mc)\n",
    "r2_mc = r2_score(y_test_mc, y_pred_mc)\n",
    "\n",
    "# Print results\n",
    "print(\"IMDb Metrics:\")\n",
    "print(f'Mean Absolute Error: {mae_im}')\n",
    "print(f'Mean Squared Error: {mse_im}')\n",
    "print(f'R^2 Score: {r2_im}')\n",
    "\n",
    "print(\"\\nRotten Tomatoes Score Metrics:\")\n",
    "print(f\"Mean Absolute Error: {mae_rt}\")\n",
    "print(f\"Mean Squared Error: {mse_rt}\")\n",
    "print(f\"R^2 Score: {r2_rt}\")\n",
    "\n",
    "print(\"\\nMetacritic Score Metrics:\")\n",
    "print(f\"Mean Absolute Error: {mae_mc}\")\n",
    "print(f\"Mean Squared Error: {mse_mc}\")\n",
    "print(f\"R^2 Score: {r2_mc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up figure with 1x3 subplots\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "# IMDb Score plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test_im, y_pred_im, alpha=0.6)\n",
    "plt.plot([y_test_im.min(), y_test_im.max()], [y_test_im.min(), y_test_im.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual IMDb Score')\n",
    "plt.ylabel('Predicted IMDb Score')\n",
    "plt.title('Actual vs. Predicted IMDb Scores')\n",
    "\n",
    "# Rotten Tomatoes plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test_rt, y_pred_rt, alpha=0.6)\n",
    "plt.plot([y_test_rt.min(), y_test_rt.max()], [y_test_rt.min(), y_test_rt.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Rotten Tomatoes Score')\n",
    "plt.ylabel('Predicted Rotten Tomatoes Score')\n",
    "plt.title('Actual vs. Predicted Rotten Tomatoes Scores')\n",
    "\n",
    "# Metacritic plot\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test_mc, y_pred_mc, alpha=0.6)\n",
    "plt.plot([y_test_mc.min(), y_test_mc.max()], [y_test_mc.min(), y_test_mc.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Metacritic Score')\n",
    "plt.ylabel('Predicted Metacritic Score')\n",
    "plt.title('Actual vs. Predicted Metacritic Scores')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# Define target columns\n",
    "target_im = 'IMDb Score'\n",
    "target_rt = 'Rotten Tomatoes Score'\n",
    "target_mc = 'Metacritic Score'\n",
    "\n",
    "targets = {\n",
    "    target_im: {},\n",
    "    target_rt: {},\n",
    "    target_mc: {}\n",
    "}\n",
    "\n",
    "for target_name, target_data in targets.items():\n",
    "    y = df[target_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler() # Create scaler *inside* the loop for each target if needed. If X is the same for all, you can keep it outside\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    targets[target_name]['X_train_scaled'] = X_train_scaled\n",
    "    targets[target_name]['X_test_scaled'] = X_test_scaled\n",
    "    targets[target_name]['y_train'] = y_train\n",
    "    targets[target_name]['y_test'] = y_test\n",
    "    targets[target_name]['scaler'] = scaler # store the scaler for later use\n",
    "\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Example values for C\n",
    "    'epsilon': [0.01, 0.1, 1],  # Example values for epsilon\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],  # Example values for kernel\n",
    "    'gamma': ['scale', 'auto'] + [0.001, 0.01, 0.1, 1] # Example values for gamma\n",
    "}\n",
    "\n",
    "for target_name, target_data in targets.items():\n",
    "    model = SVR()\n",
    "    halving_search = HalvingGridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, factor=2, min_resources=50)\n",
    "    halving_search.fit(target_data['X_train_scaled'], target_data['y_train'])\n",
    "    best_model = halving_search.best_estimator_\n",
    "\n",
    "    # Make predictions using the best model\n",
    "    y_pred = best_model.predict(target_data['X_test_scaled'])\n",
    "\n",
    "    # Evaluate the best model\n",
    "    mae = mean_absolute_error(target_data['y_test'], y_pred)\n",
    "    mse = mean_squared_error(target_data['y_test'], y_pred)\n",
    "    r2 = r2_score(target_data['y_test'], y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{target_name} Metrics:\")\n",
    "    print(f'Best parameters: {halving_search.best_params_}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R^2 Score: {r2}')\n",
    "    \n",
    "    targets[target_name]['best_model'] = best_model\n",
    "    targets[target_name]['grid_search'] = halving_search # Store the grid search object if needed for more detailed analysis\n",
    "\n",
    "#Example of using the trained models:\n",
    "#print(targets[target_im]['best_model'].predict(targets[target_im]['scaler'].transform([[...some new data point...]]))) # Remember to scale new data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up figure with 1x3 subplots\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "target_names = [target_im, target_rt, target_mc]  # List of target names for easier looping\n",
    "\n",
    "for i, target_name in enumerate(target_names):\n",
    "    # Get the best model and data for the current target\n",
    "    best_model = targets[target_name]['best_model']\n",
    "    y_test = targets[target_name]['y_test']\n",
    "    X_test_scaled = targets[target_name]['X_test_scaled']\n",
    "\n",
    "    # Make predictions using the best model\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "    # Create the subplot\n",
    "    plt.subplot(1, 3, i + 1)  # i+1 because subplot indexing starts from 1\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel(f'Actual {target_name}')  # Use f-string for dynamic label\n",
    "    plt.ylabel(f'Predicted {target_name}')\n",
    "    plt.title(f'Actual vs. Predicted {target_name}s') # Added \"s\" for plural\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show() # added to show the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
