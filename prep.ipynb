{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplikate\n",
    "Es gibt keine Duplikate in Zeilen und keine in Reihen.\n",
    "\n",
    "### Nicht relevante Daten:\n",
    "- Languages\n",
    "- Netflix Link\t\n",
    "- IMDb Link\t\n",
    "- Summary\n",
    "- Image\n",
    "- Poster\n",
    "- TMDb Trailer\t\n",
    "- Trailer Site\n",
    "- Tags\n",
    "- Country Availability\n",
    "- Director\n",
    "- Writer\n",
    "- Actors\n",
    "\n",
    "Da diese String Werte sind und schwer bzw. gar nicht encoded werden können\n",
    "\n",
    "### Ausreißer\n",
    "Bei Rotten Tomatoes score gibt es 0 Werte.\n",
    "Sonst gibt keine Ausreißer, aber manche Filme wurden im Vergleich zu anderen sehr oft bewertet.\n",
    "\n",
    "### Vorverarbeitungsschritte\n",
    "- Series or Movie kann Ordinal Encoded werden\n",
    "- View Rating kann Ordinal Encoded werden\n",
    "- Genre kann One-Hot Encoded werden\n",
    "- Runtime kann zu <30 min -> 1, 1-2h -> 3 encoded werden\n",
    "- Release Date kann zu Unix Date umgewandelt werden\n",
    "- Boxoffice kann von String zu Number convertiert werden\n",
    "- NaN Werte in Awards Nominated For kann auf 0 gesetzt werden.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "file_path = './archive/netflix-rotten-tomatoes-metacritic-imdb.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Awards Nominated For'] = df['Awards Nominated For'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only string columns\n",
    "string_columns = df.select_dtypes(include=[object])\n",
    "\n",
    "# Print the string columns\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Languages', 'Netflix Link', 'IMDb Link', 'Summary', 'Image', 'Poster', 'TMDb Trailer', 'Trailer Site', 'Tags', 'Country Availability', 'Production House','Director','Writer','Actors']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'Runtime' column\n",
    "df['Runtime'] = df['Runtime'].replace({'< 30 minutes': 1, '30-60 mins': 2, '1-2 hour': 3, '> 2 hours': 5, '> 2 hrs': 5})\n",
    "\n",
    "df['Runtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Define the mapping dictionary for view ratings to minimum age\n",
    "df['View Rating'] = df['View Rating'].fillna('Unrated')\n",
    "view_rating_to_age = {\n",
    "    'G': 0,\n",
    "    'E10+': 10,\n",
    "    'TV-Y7-FV': 7,\n",
    "    'PG': 10,\n",
    "    'PG-13': 13,\n",
    "    'R': 17,\n",
    "    'NC-17': 17,\n",
    "    'MA-17': 17,\n",
    "    'Approved': 0,\n",
    "    'Passed': 0,\n",
    "    'Unrated': 0,\n",
    "    'UNRATED': 0,\n",
    "    'E': 0,\n",
    "    'Not Rated': 0,\n",
    "    'NOTRATED': 0,\n",
    "    'NOT RATED': 0,\n",
    "    'TV-Y': 0,\n",
    "    'TV-Y7': 7,\n",
    "    'TV-G': 0,\n",
    "    'AL': 0,\n",
    "    'GP': 0,\n",
    "    'TV-PG': 10,\n",
    "    'TV-14': 14,\n",
    "    'M/PG': 15,\n",
    "    '15': 15,\n",
    "    'U': 0,\n",
    "    'M': 15,\n",
    "    'TV-MA': 17,\n",
    "    'X': 18,\n",
    "    'TV-13': 13,\n",
    "}\n",
    "\n",
    "# Convert 'View Rating' to minimum age\n",
    "df['Minimum Age'] = df['View Rating'].replace(view_rating_to_age)\n",
    "df = df.drop('View Rating', axis=1)\n",
    "\n",
    "# Display the count of each rating\n",
    "df['Minimum Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-numeric characters and convert to float\n",
    "df['Boxoffice'] = df['Boxoffice'].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "# Display the 'Boxoffice' column to verify the changes\n",
    "df['Boxoffice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Series or Movie' to 0 for movies and 1 for series\n",
    "df['Series or Movie'] = df['Series or Movie'].replace({'Movie': 0, 'Series': 1})\n",
    "# Rename the column to 'Is Series'\n",
    "df.rename(columns={'Series or Movie': 'Is Series'}, inplace=True)\n",
    "# Display the updated column to verify the changes\n",
    "\n",
    "df['Is Series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['Release Date'].isna() & df['Netflix Release Date'].isna()]\n",
    "nan_counts = df['Release Date'].isna().sum()\n",
    "print(x)\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Release Date'] = pd.to_datetime(df['Release Date'], errors='coerce')\n",
    "df['Release Date'] = pd.to_datetime(df['Netflix Release Date'], errors='coerce', dayfirst=False)\n",
    "\n",
    "df['Release Date'] = df['Release Date'].fillna(df['Netflix Release Date'])\n",
    "df['Release Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Print all rows where 'Release Date' is NaN and 'Netflix Release Date' is not\n",
    "\n",
    "\n",
    "\n",
    "# Convert 'Release Date' to Unix timestamp (int) in seconds, only for non-NaT values\n",
    "df['Release Date'] = df['Release Date'].where(df['Release Date'].isna(), df['Release Date'].view('int64') // 10**9)\n",
    "\n",
    "# Replace NaT with np.nan (for consistency)\n",
    "df['Release Date'] = df['Release Date'].where(df['Release Date'].notna(), np.nan)\n",
    "\n",
    "# Print the count of NaN values in each column\n",
    "df = df.drop('Netflix Release Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all columns of all rows with NaN values\n",
    "# Print percentage of NaN values in each column\n",
    "nan_percentage = df.isna().mean() * 100\n",
    "nan_percentage = nan_percentage.to_frame(name='Percentage of NaN Values')\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "nan_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only numeric columns\n",
    "numeric_data = df.select_dtypes(include=[float, int])\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = numeric_data.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "genre_one_hot = df['Genre'].str.split(',').apply(lambda x: [item.strip() for item in x])\n",
    "onehot_encoded = genre_one_hot.explode().str.get_dummies().groupby(level=0).sum()\n",
    "df = pd.concat([df, onehot_encoded], axis=1)\n",
    "\n",
    "df = df.drop('Genre', axis=1)\n",
    "\n",
    "onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the numeric data\n",
    "scaled_numeric_data = scaler.fit_transform(numeric_data)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "scaled_numeric_data = pd.DataFrame(scaled_numeric_data, columns=numeric_data.columns)\n",
    "\n",
    "scaled_numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a horizontal boxplot for the numeric data\n",
    "sns.boxplot(data=scaled_numeric_data, orient='h')\n",
    "plt.title('Horizontal Boxplot of Numeric Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a horizontal boxplot for the numeric data\n",
    "sns.boxplot(data=numeric_data, orient='h')\n",
    "plt.title('Horizontal Boxplot of Numeric Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "votes = np.log1p(numeric_data)\n",
    "sns.boxplot(data=votes, orient='h')\n",
    "plt.title('Horizontal Boxplot of Numeric Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only string columns\n",
    "string_columns = df.select_dtypes(include=[object])\n",
    "\n",
    "# Print the string columns\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End\n",
    "\n",
    "Continue [regression](./ML/tree.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Select the features and target variable\n",
    "features = df.select_dtypes(include=[float, int]).drop(columns=['IMDb Score'])\n",
    "# features = df[['Is Series', 'Hidden Gem Score', 'Runtime', 'Rotten Tomatoes Score', 'Metacritic Score', 'Awards Received', 'Awards Nominated For', 'Boxoffice', 'Release Date', 'IMDb Votes', 'Minimum Age']]\n",
    "target = df['IMDb Score']\n",
    "\n",
    "# Drop rows with missing values in features or target\n",
    "features = features.dropna()\n",
    "target = target[features.index]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of actual vs. predicted IMDb scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual IMDb Score')\n",
    "plt.ylabel('Predicted IMDb Score')\n",
    "plt.title('Actual vs. Predicted IMDb Scores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Round the predicted and actual IMDb scores to the nearest integer\n",
    "y_pred_rounded = np.round(y_pred)\n",
    "y_test_rounded = np.round(y_test)\n",
    "\n",
    "# Create the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_rounded, y_pred_rounded)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test_rounded), yticklabels=np.unique(y_test_rounded))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select the features and target variable\n",
    "features = df[['Hidden Gem Score', 'Runtime', 'Rotten Tomatoes Score', 'Metacritic Score', 'Awards Received', 'Boxoffice', 'IMDb Votes']]\n",
    "target = df['IMDb Score']\n",
    "\n",
    "# Drop rows with missing values in features or target\n",
    "features = features.dropna()\n",
    "target = target[features.index]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Scatter plot of actual vs. predicted IMDb scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual IMDb Score')\n",
    "plt.ylabel('Predicted IMDb Score')\n",
    "plt.title('Actual vs. Predicted IMDb Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# # Create and train the decision tree regressor\n",
    "# tree_model = DecisionTreeRegressor(random_state=42)\n",
    "# tree_model.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# # Evaluate the decision tree model\n",
    "# tree_mse = mean_squared_error(y_test, y_tree_pred)\n",
    "# tree_r2 = r2_score(y_test, y_tree_pred)\n",
    "\n",
    "# print(f'Decision Tree Mean Squared Error: {tree_mse}')\n",
    "# print(f'Decision Tree R-squared: {tree_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree\n",
    "# import dtreeviz\n",
    "\n",
    "# # Set the size of the plot\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# # Plot the decision tree with a maximum depth of 3\n",
    "# # Visualize the decision tree with dtreeviz\n",
    "# viz = dtreeviz.model(tree_model, X_train, y_train,\n",
    "#                target_name='IMDb Score',\n",
    "#                feature_names=features.columns)\n",
    "\n",
    "# # Display the visualization\n",
    "# viz.view()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
